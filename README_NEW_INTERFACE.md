# Nouvelle Interface Interactive Monty Hall

## üéÆ Fonctionnalit√©s

La nouvelle interface PyGame offre une exp√©rience utilisateur moderne et intuitive pour le probl√®me de Monty Hall :

### 1. **S√©lection d'Environnement**
- **Monty Hall 1** : Version classique avec 3 portes
- **Monty Hall 2** : Version √©tendue avec 5 portes et √©tapes multiples

### 2. **Choix du Mode de Jeu**
- **Mode Humain** : Jouez vous-m√™me en cliquant sur les portes
- **Mode Agent** : Laissez l'IA jouer pour vous

### 3. **S√©lection d'Algorithme** (Mode Agent uniquement)
- **Q-Learning** : Apprentissage par renforcement avec exploration
- **SARSA** : State-Action-Reward-State-Action
- **Value Iteration** : It√©ration de valeurs pour politique optimale

## üöÄ Comment Lancer

### Lancement Simple
```bash
python src/visualization/run_monty_hall.py
```

### Tests
```bash
python test_new_interface.py
```

## üéØ Workflow Utilisateur

1. **√âcran d'accueil** : S√©lectionnez l'environnement (Monty Hall 1 ou 2)
2. **Choix du mode** : 
   - Cliquez sur "MODE HUMAIN" pour jouer vous-m√™me
   - Cliquez sur "MODE AGENT" pour l'IA
3. **S√©lection d'algorithme** (si mode agent) : Choisissez l'algorithme d'apprentissage
4. **Jeu** : Observez l'agent jouer ou jouez vous-m√™me

## üé® Interface Utilisateur

### Design Moderne
- **Fond d√©grad√©** : Interface visuellement attrayante
- **Boutons interactifs** : Effets de survol et couleurs dynamiques
- **Navigation intuitive** : Boutons "Retour" et raccourcis clavier (√âchap)

### Informations en Temps R√©el
- **Statut de l'√©pisode** : Num√©ro d'√©pisode actuel
- **Compteur de victoires** : Suivi des performances
- **Mode et algorithme** : Affichage des param√®tres actuels

## üîß Architecture Technique

### Structure des Fichiers
```
src/
‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îú‚îÄ‚îÄ monty_hall_visualizer.py    # Interface PyGame principale
‚îÇ   ‚îî‚îÄ‚îÄ run_monty_hall.py          # Script de lancement
‚îú‚îÄ‚îÄ rl_environments/
‚îÇ   ‚îú‚îÄ‚îÄ monty_hall_interactive.py   # Monty Hall 1
‚îÇ   ‚îî‚îÄ‚îÄ monty_hall2_stepbystep.py   # Monty Hall 2
‚îî‚îÄ‚îÄ rl_algorithms/
    ‚îú‚îÄ‚îÄ q_learning.py              # Algorithme Q-Learning
    ‚îú‚îÄ‚îÄ sarsa.py                   # Algorithme SARSA
    ‚îî‚îÄ‚îÄ value_iteration.py         # Algorithme Value Iteration
```

### Fonctionnalit√©s Cl√©s

#### D√©tection Automatique des Algorithmes
```python
def get_available_algorithms(self) -> List[str]:
    """D√©tecte automatiquement les algorithmes disponibles."""
    # Import dynamique et d√©tection des classes disponibles
```

#### Menus Interactifs
- **Menu principal** : S√©lection mode humain/agent
- **Menu algorithmes** : Choix de l'algorithme d'apprentissage
- **Menu environnements** : S√©lection Monty Hall 1 ou 2

#### Gestion des √âtats
- **√âtats de jeu** : Gestion des diff√©rentes phases du jeu
- **√âtats d'interface** : Navigation entre les menus
- **√âtats d'agent** : Entra√Ænement et s√©lection d'actions

## üéØ Exemples d'Utilisation

### Mode Humain
1. Lancez le script
2. S√©lectionnez l'environnement
3. Choisissez "MODE HUMAIN"
4. Jouez en cliquant sur les portes

### Mode Agent
1. Lancez le script
2. S√©lectionnez l'environnement
3. Choisissez "MODE AGENT"
4. S√©lectionnez l'algorithme (Q-Learning, SARSA, ou Value Iteration)
5. Observez l'agent jouer automatiquement

## üîç D√©tails Techniques

### Algorithmes Support√©s
- **Q-Learning** : 1000 √©pisodes d'entra√Ænement pour MH1, 2000 pour MH2
- **SARSA** : 1000 √©pisodes d'entra√Ænement pour MH1, 2000 pour MH2
- **Value Iteration** : Convergence automatique

### Param√®tres par D√©faut
- **Learning Rate** : 0.1
- **Gamma (discount factor)** : 0.9
- **Epsilon (exploration)** : 0.1
- **Nombre d'√©pisodes de jeu** : 3

### Gestion des Erreurs
- **Import dynamique** : Gestion gracieuse des modules manquants
- **Fallback** : Valeurs par d√©faut en cas d'erreur
- **Fermeture propre** : Gestion des √©v√©nements de fermeture

## üöÄ Am√©liorations Futures

### Fonctionnalit√©s Possibles
- [ ] Sauvegarde/chargement des agents entra√Æn√©s
- [ ] Comparaison de performances entre algorithmes
- [ ] Param√®tres configurables (learning rate, epsilon, etc.)
- [ ] Visualisation des matrices Q-values
- [ ] Mode comp√©tition entre agents

### Optimisations
- [ ] Interface plus fluide avec animations
- [ ] Support pour d'autres environnements
- [ ] Export des r√©sultats en CSV/JSON
- [ ] Mode batch pour tests automatis√©s

## üìù Notes de D√©veloppement

### Changements Majeurs
1. **Refactoring complet** : S√©paration claire des responsabilit√©s
2. **Interface unifi√©e** : Un seul script pour tous les environnements
3. **D√©tection automatique** : Plus besoin de sp√©cifier les algorithmes manuellement
4. **UX am√©lior√©e** : Navigation intuitive et design moderne

### Compatibilit√©
- **Python 3.7+** : Compatible avec les versions r√©centes
- **Pygame 2.0+** : Interface graphique moderne
- **Syst√®mes** : Windows, macOS, Linux

---

**D√©velopp√© avec ‚ù§Ô∏è pour l'apprentissage par renforcement** 