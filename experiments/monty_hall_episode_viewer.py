#!/usr/bin/env python3
"""
Visualiseur d'Ã©pisodes Monty Hall avec PyGame - Permet de voir le dÃ©roulement Ã©tape par Ã©tape.
"""

import sys
import os
import time
import numpy as np

# Ajouter le rÃ©pertoire parent au path pour importer les modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from environments.monty_hall import MontyHall
from environments.visualization.monty_hall_visualizer import MontyHallVisualizer
from algorithms.dynamic_programming.value_iteration import ValueIteration

def train_agent():
    """EntraÃ®ne un agent Value Iteration."""
    print("EntraÃ®nement de l'agent...")
    
    env = MontyHall()
    agent = ValueIteration(
        environment=env,
        discount_factor=0.9,
        theta=0.001,
        max_iterations=1000
    )
    
    results = agent.train()
    print(f"Agent entraÃ®nÃ© en {results['iterations']} itÃ©rations!")
    
    return agent

def view_episode_step_by_step(env, visualizer, agent=None, mode="agent", episode_num=1):
    """Visualise un Ã©pisode Ã©tape par Ã©tape."""
    print(f"\n=== Ã‰pisode {episode_num} - Mode: {mode} ===")
    
    state = env.reset()
    total_reward = 0
    steps = 0
    actions_taken = []
    
    print("DÃ©but de l'Ã©pisode - Appuyez sur ENTRÃ‰E pour continuer...")
    
    while True:
        # Afficher l'Ã©tat actuel
        episode_info = {
            "Ã‰pisode": episode_num,
            "Mode": mode,
            "Ã‰tapes": steps,
            "RÃ©compense": total_reward,
            "Actions": actions_taken,
            "Ã‰tat": env.state,
            "Instruction": "Appuyez sur ENTRÃ‰E pour continuer"
        }
        visualizer.render_monty_hall_state(env, episode_info)
        
        # Attendre l'action de l'utilisateur
        waiting_for_input = True
        while waiting_for_input and visualizer.running:
            event = visualizer.handle_events()
            if event == "step":
                waiting_for_input = False
            elif event == "pause":
                # Afficher l'Ã©tat en pause
                episode_info["Instruction"] = "PAUSE - Appuyez sur ESPACE pour continuer"
                visualizer.render_monty_hall_state(env, episode_info)
            elif not visualizer.running:
                return None
        
        if not visualizer.running:
            return None
        
        # Choisir l'action
        if env.state == 0:
            # Choix initial de porte
            if mode == "agent":
                action = np.random.choice([0, 1, 2])
                action_name = f"Choisir porte {action}"
            else:
                # Mode alÃ©atoire pour comparaison
                action = np.random.choice([0, 1, 2])
                action_name = f"Choisir porte {action}"
        else:
            # Action rester/changer
            if mode == "agent":
                action = np.argmax(agent.policy[state])
                action_name = "Changer" if action == 1 else "Garder"
            else:
                # Mode alÃ©atoire pour comparaison
                action = np.random.choice([0, 1])
                action_name = "Changer" if action == 1 else "Garder"
        
        actions_taken.append(action)
        
        print(f"Ã‰tape {steps + 1}: {action_name}")
        
        # ExÃ©cuter l'action
        old_state = env.state
        state, reward, done, info = env.step(action)
        total_reward += reward
        steps += 1
        
        # Afficher le rÃ©sultat de l'action
        episode_info = {
            "Ã‰pisode": episode_num,
            "Mode": mode,
            "Ã‰tapes": steps,
            "RÃ©compense": total_reward,
            "Actions": actions_taken,
            "Ã‰tat": env.state,
            "DerniÃ¨re action": action_name,
            "RÃ©compense Ã©tape": reward
        }
        visualizer.render_monty_hall_state(env, episode_info)
        
        # Pause pour voir le rÃ©sultat
        time.sleep(1.5)
        
        if done:
            # Afficher le rÃ©sultat final
            result = "GAGNÃ‰! ğŸ‰" if info.get("result") == "win" else "PERDU! âŒ"
            episode_info = {
                "Ã‰pisode": episode_num,
                "Mode": mode,
                "Ã‰tapes": steps,
                "RÃ©compense": total_reward,
                "Actions": actions_taken,
                "RÃ©sultat": result,
                "Temps total": f"{steps} Ã©tapes"
            }
            visualizer.render_monty_hall_state(env, episode_info)
            
            print(f"Ã‰pisode terminÃ©: {result}")
            print(f"RÃ©compense totale: {total_reward}")
            print(f"Nombre d'Ã©tapes: {steps}")
            
            # Pause pour voir le rÃ©sultat final
            time.sleep(3.0)
            break
    
    return info.get("result") == "win"

def main_episode_viewer():
    """Visualiseur principal d'Ã©pisodes."""
    print("=== VISUALISEUR D'Ã‰PISODES MONTY HALL ===")
    print("Ce script permet de voir le dÃ©roulement des Ã©pisodes Ã©tape par Ã©tape.")
    print("ContrÃ´les:")
    print("- ENTRÃ‰E: Passer Ã  l'Ã©tape suivante")
    print("- ESPACE: Pause/Reprendre")
    print("- Ã‰CHAP: Quitter")
    
    # CrÃ©er l'environnement et le visualiseur
    env = MontyHall()
    visualizer = MontyHallVisualizer()
    
    # EntraÃ®ner l'agent
    agent = train_agent()
    
    # Statistiques
    agent_wins = 0
    random_wins = 0
    agent_games = 0
    random_games = 0
    
    print("\nCommenÃ§ons par voir quelques Ã©pisodes de l'agent entraÃ®nÃ©...")
    
    # Voir quelques Ã©pisodes de l'agent
    for episode in range(1, 4):
        result = view_episode_step_by_step(env, visualizer, agent, "agent", episode)
        if result is not None:
            agent_games += 1
            if result:
                agent_wins += 1
        else:
            break
    
    if agent_games > 0:
        print(f"\nAgent: {agent_wins}/{agent_games} ({agent_wins/agent_games*100:.1f}%)")
    
    print("\nMaintenant, voyons quelques Ã©pisodes avec un agent alÃ©atoire pour comparaison...")
    
    # Voir quelques Ã©pisodes alÃ©atoires
    for episode in range(1, 4):
        result = view_episode_step_by_step(env, visualizer, None, "alÃ©atoire", episode)
        if result is not None:
            random_games += 1
            if result:
                random_wins += 1
        else:
            break
    
    if random_games > 0:
        print(f"\nAlÃ©atoire: {random_wins}/{random_games} ({random_wins/random_games*100:.1f}%)")
    
    # Comparaison finale
    if agent_games > 0 and random_games > 0:
        print(f"\n=== COMPARAISON FINALE ===")
        print(f"Agent entraÃ®nÃ©: {agent_wins}/{agent_games} ({agent_wins/agent_games*100:.1f}%)")
        print(f"Agent alÃ©atoire: {random_wins}/{random_games} ({random_wins/random_games*100:.1f}%)")
        
        if agent_wins/agent_games > random_wins/random_games:
            print("L'agent entraÃ®nÃ© fait mieux que l'agent alÃ©atoire!")
        elif random_wins/random_games > agent_wins/agent_games:
            print("L'agent alÃ©atoire fait mieux que l'agent entraÃ®nÃ©!")
        else:
            print("Les deux agents ont les mÃªmes performances!")
    
    # Afficher la politique de l'agent
    print(f"\nPolitique de l'agent entraÃ®nÃ©:")
    for state in range(len(env.S)):
        if state not in env.T:
            action = np.argmax(agent.policy[state])
            action_name = "Changer" if action == 1 else "Garder"
            value = agent.V[state]
            print(f"Ã‰tat {state}: {action_name} (V(s) = {value:.3f})")
    
    # Attendre que l'utilisateur ferme la fenÃªtre
    print("\nAppuyez sur Ã‰CHAP ou fermez la fenÃªtre pour quitter...")
    while visualizer.running:
        event = visualizer.handle_events()
        if event is not None:
            break
        time.sleep(0.1)
    
    visualizer.quit()

if __name__ == "__main__":
    main_episode_viewer() 