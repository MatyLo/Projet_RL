{
  "experiment": {
    "name": "lineworld_q_learning_baseline",
    "description": "Configuration de base pour Q-Learning sur LineWorld",
    "version": "1.0",
    "tags": ["baseline", "lineworld", "q_learning"],
    "author": "RL Team",
    "created_date": "2025-01-20",
    "notes": "Configuration optimisée pour convergence rapide sur LineWorld"
  },
  
  "environment": {
    "type": "lineworld",
    "line_length": 5,
    "start_position": 0,
    "target_position": 4,
    "reward_target": 10.0,
    "reward_step": -0.1,
    "reward_boundary": -1.0,
    "max_steps": 100,
    "random_start": false,
    "description": "Ligne de 5 positions, agent commence en 0, cible en 4"
  },
  
  "algorithms": {
    "q_learning": {
      "learning_rate": 0.1,
      "gamma": 0.9,
      "epsilon": 0.1,
      "epsilon_decay": 0.995,
      "epsilon_min": 0.01,
      "num_episodes": 1000,
      "initial_q_value": 0.0,
      "convergence_threshold": 1e-4,
      "convergence_check_interval": 100,
      "description": "Paramètres optimisés pour convergence rapide"
    },
    
    "sarsa": {
      "learning_rate": 0.1,
      "gamma": 0.9,
      "epsilon": 0.1,
      "epsilon_decay": 0.995,
      "epsilon_min": 0.01,
      "num_episodes": 1000,
      "description": "Configuration SARSA pour comparaison avec Q-Learning"
    },
    
    "q_learning_fast": {
      "learning_rate": 0.3,
      "gamma": 0.95,
      "epsilon": 0.3,
      "epsilon_decay": 0.99,
      "epsilon_min": 0.05,
      "num_episodes": 500,
      "initial_q_value": 0.0,
      "description": "Version accélérée pour tests rapides"
    },
    
    "q_learning_conservative": {
      "learning_rate": 0.05,
      "gamma": 0.99,
      "epsilon": 0.05,
      "epsilon_decay": 0.9995,
      "epsilon_min": 0.001,
      "num_episodes": 2000,
      "initial_q_value": 0.0,
      "description": "Version conservatrice pour environnements complexes"
    }
  },
  
  "training": {
    "save_frequency": 100,
    "evaluation_frequency": 50,
    "verbose": true,
    "save_models": true,
    "save_training_stats": true,
    "save_q_tables": true,
    "render_frequency": 0,
    "description": "Paramètres d'entraînement et de sauvegarde"
  },
  
  "evaluation": {
    "num_episodes": 100,
    "max_steps_per_episode": 100,
    "render": false,
    "verbose": true,
    "save_results": true,
    "description": "Paramètres d'évaluation des performances"
  },
  
  "demonstration": {
    "num_episodes": 3,
    "step_by_step": true,
    "render_mode": "console",
    "delay_between_steps": 1.0,
    "save_demo_sequence": true,
    "show_q_values": true,
    "show_policy": true,
    "description": "Paramètres pour démonstrations et soutenance"
  },
  
  "human_mode": {
    "show_rewards": true,
    "show_q_values": false,
    "highlight_valid_actions": true,
    "interface_type": "console",
    "instructions": "Utilisez les touches 0 (Gauche) et 1 (Droite) pour vous déplacer",
    "description": "Configuration pour le mode agent humain"
  },
  
  "visualization": {
    "console": {
      "show_state_numbers": true,
      "show_rewards": true,
      "show_episode_stats": true,
      "clear_screen": false
    },
    "pygame": {
      "window_width": 800,
      "window_height": 200,
      "cell_size": 120,
      "colors": {
        "background": [240, 240, 240],
        "agent": [0, 100, 200],
        "target": [200, 100, 0],
        "empty": [255, 255, 255],
        "border": [100, 100, 100],
        "text": [0, 0, 0]
      },
      "show_state_numbers": true,
      "show_rewards": true,
      "animation_speed": 500
    }
  },
  
  "outputs": {
    "base_dir": "outputs",
    "models_dir": "models",
    "results_dir": "results",
    "plots_dir": "plots",
    "demos_dir": "demos",
    "timestamp_files": true,
    "description": "Configuration des chemins de sortie"
  },
  
  "comparison_experiments": {
    "algorithms_to_compare": ["q_learning", "sarsa", "q_learning_fast"],
    "metrics": ["avg_reward", "convergence_speed", "final_performance", "episode_length"],
    "num_runs": 5,
    "description": "Configuration pour comparaisons systématiques"
  },
  
  "hyperparameter_study": {
    "algorithm": "q_learning",
    "parameters": {
      "learning_rate": [0.01, 0.05, 0.1, 0.2, 0.3],
      "epsilon": [0.05, 0.1, 0.15, 0.2, 0.3],
      "gamma": [0.8, 0.9, 0.95, 0.99]
    },
    "search_type": "grid",
    "max_combinations": 50,
    "description": "Configuration pour exploration d'hyperparamètres"
  }
}