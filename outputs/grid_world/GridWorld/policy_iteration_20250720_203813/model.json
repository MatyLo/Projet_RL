{
  "algorithm": "PolicyIteration",
  "state_space_size": 25,
  "action_space_size": 4,
  "gamma": 0.9,
  "theta": 1e-06,
  "is_trained": true,
  "value_function": [
    0.47829690000000014,
    0.5314410000000002,
    0.5904900000000002,
    0.6561000000000001,
    0.0,
    0.5314410000000002,
    0.5904900000000002,
    0.6561000000000001,
    0.7290000000000001,
    0.81,
    0.5904900000000002,
    0.6561000000000001,
    0.7290000000000001,
    0.81,
    0.9,
    0.6561000000000001,
    0.7290000000000001,
    0.81,
    0.9,
    1.0,
    0.7290000000000001,
    0.81,
    0.9,
    1.0,
    0.0
  ],
  "policy": [
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.25,
      0.25,
      0.25,
      0.25
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      1.0,
      0.0,
      0.0
    ],
    [
      0.0,
      0.0,
      0.0,
      1.0
    ],
    [
      0.0,
      0.0,
      0.0,
      1.0
    ],
    [
      0.0,
      0.0,
      0.0,
      1.0
    ],
    [
      0.0,
      0.0,
      0.0,
      1.0
    ],
    [
      0.25,
      0.25,
      0.25,
      0.25
    ]
  ],
  "q_function": [
    [
      0.43046721000000016,
      0.47829690000000014,
      0.43046721000000016,
      0.47829690000000014
    ],
    [
      0.47829690000000014,
      0.5314410000000002,
      0.43046721000000016,
      0.5314410000000002
    ],
    [
      0.5314410000000002,
      0.5904900000000002,
      0.47829690000000014,
      0.5904900000000002
    ],
    [
      0.5904900000000002,
      0.6561000000000001,
      0.5314410000000002,
      -3.0
    ],
    [
      -3.0,
      -3.0,
      -3.0,
      -3.0
    ],
    [
      0.43046721000000016,
      0.5314410000000002,
      0.47829690000000014,
      0.5314410000000002
    ],
    [
      0.47829690000000014,
      0.5904900000000002,
      0.47829690000000014,
      0.5904900000000002
    ],
    [
      0.5314410000000002,
      0.6561000000000001,
      0.5314410000000002,
      0.6561000000000001
    ],
    [
      0.5904900000000002,
      0.7290000000000001,
      0.5904900000000002,
      0.7290000000000001
    ],
    [
      -3.0,
      0.81,
      0.6561000000000001,
      0.7290000000000001
    ],
    [
      0.47829690000000014,
      0.5904900000000002,
      0.5314410000000002,
      0.5904900000000002
    ],
    [
      0.5314410000000002,
      0.6561000000000001,
      0.5314410000000002,
      0.6561000000000001
    ],
    [
      0.5904900000000002,
      0.7290000000000001,
      0.5904900000000002,
      0.7290000000000001
    ],
    [
      0.6561000000000001,
      0.81,
      0.6561000000000001,
      0.81
    ],
    [
      0.7290000000000001,
      0.9,
      0.7290000000000001,
      0.81
    ],
    [
      0.5314410000000002,
      0.6561000000000001,
      0.5904900000000002,
      0.6561000000000001
    ],
    [
      0.5904900000000002,
      0.7290000000000001,
      0.5904900000000002,
      0.7290000000000001
    ],
    [
      0.6561000000000001,
      0.81,
      0.6561000000000001,
      0.81
    ],
    [
      0.7290000000000001,
      0.9,
      0.7290000000000001,
      0.9
    ],
    [
      0.81,
      1.0,
      0.81,
      0.9
    ],
    [
      0.5904900000000002,
      0.6561000000000001,
      0.6561000000000001,
      0.7290000000000001
    ],
    [
      0.6561000000000001,
      0.7290000000000001,
      0.6561000000000001,
      0.81
    ],
    [
      0.7290000000000001,
      0.81,
      0.7290000000000001,
      0.9
    ],
    [
      0.81,
      0.9,
      0.81,
      1.0
    ],
    [
      1.0,
      1.0,
      1.0,
      1.0
    ]
  ],
  "convergence_history": [
    {
      "iteration": 0,
      "policy_stable": false,
      "max_value": 0.3778997049968792
    },
    {
      "iteration": 1,
      "policy_stable": false,
      "max_value": 1.0
    },
    {
      "iteration": 2,
      "policy_stable": true,
      "max_value": 1.0
    }
  ],
  "training_history": [
    {
      "episode": 1,
      "reward": 0.6717219560000001,
      "steps": 3
    }
  ]
}