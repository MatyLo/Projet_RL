{
  "algorithm": "PolicyIteration",
  "state_space_size": 5,
  "action_space_size": 2,
  "gamma": 0.85,
  "theta": 1e-06,
  "is_trained": true,
  "value_function": [
    0.0,
    0.7224999999999999,
    0.85,
    1.0,
    0.0
  ],
  "policy": [
    [
      0.5,
      0.5
    ],
    [
      0.0,
      1.0
    ],
    [
      0.0,
      1.0
    ],
    [
      0.0,
      1.0
    ],
    [
      0.5,
      0.5
    ]
  ],
  "q_function": [
    [
      0.0,
      0.0
    ],
    [
      -1.0,
      0.7224999999999999
    ],
    [
      0.6141249999999999,
      0.85
    ],
    [
      0.7224999999999999,
      1.0
    ],
    [
      0.0,
      0.0
    ]
  ],
  "convergence_history": [
    {
      "iteration": 0,
      "policy_stable": false,
      "max_value": 0.5000001320703141
    },
    {
      "iteration": 1,
      "policy_stable": true,
      "max_value": 1.0
    }
  ],
  "training_history": [
    {
      "episode": 1,
      "reward": 0.5145,
      "steps": 2
    }
  ]
}